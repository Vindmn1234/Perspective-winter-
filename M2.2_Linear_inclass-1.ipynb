{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/c7zwmp_n0n926g9h2sj4fj3w0000gn/T/ipykernel_12245/1398990587.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e585c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb60lEQVR4nO3de7xVdZ3/8ddbQLxgAnKGQZRARR3GR5Ieb2WmkuWlEepnauOvqAcNmVZW0xTaw7LHNDM4NTnN/FKjvJwaL6jpD9IpJbxlk+RBUcHLD0IQlctRI2+lqZ/fH+u7Zbs5+5x1jqy9z2a9n4/HeZx1X5+9OLz32t+91ncpIjAzs/LYptkFmJlZYzn4zcxKxsFvZlYyDn4zs5Jx8JuZlYyD38ysZBz8VmqSQtJeDdjPeZL+Kw2Pk/SCpEFbaNsXSzo3DR8p6Yktsd20vfdIenRLbc8GBge/1ZXCqfLzuqQ/Vo2f1qAatmiQDQQR8XhEDIuI13paTtInJN2VY3unR8Q/bonaat8II+JXEbHPlti2DRyDm12ADVwRMawyLGkV8KmI+GVftiFpcES8uqVrs4ykQb29gZjV8hm/9ZmkgyX9RtJGSWsl/R9J21bND0lnSloOLE/TvpKWfUrSp6rPLCUNlfQdSY9LWp+aLraXtCPwc2DXqk8au9bUcoikddXNJpI+JOmBPLXWbOt2SZ+qGn/TGbekfSUtkPSspEclndzDMZog6Q5Jz0taAIyqmjc+vf7BVftZmZZ9TNJpkv4KuBg4LL3ujWnZyyVdJOm/Jb0IHJWmfatm/+dIelrSqupPZz29Rkl3psn3p32eUvuJS9JfpW1slLRM0olV8y6X9H1JN6XXskjSnvWOkTWPg9/64zXgi2RhdhgwBTijZplpwCHAJEnHAl8C3gfsBRxZs+xsYG9gcpo/Fvh6RLwIHAc8lZpGhkXEU9UrRsQi4EXg6KrJfwtc2Ydae5XehBak7f4FcCpwoaRJdVa5Elic9vuPwPQetvsfwHERsRPwLmBJRDwMnA78Jr3u4TWv75+AnYDumoL+Mu13bNrvHEm9NtdExBFpcP+0z7k1tQ4BfgbcQnYMPgdcUbPtU4FvAiOAFalOG2Ac/NZnEbE4Iu6OiFcjYhXwA+C9NYv9S0Q8GxF/BE4GLouIZRHxEnBeZSFJAmYCX0zLPw/8M1mA5HUV8NG0vZ2A49O0vLXm8UFgVURclrZ1H/BT4CO1C0oaBxwEnBsRL0fEnWSBWc/rwH6Sto+ItRGxrJda5kXEryPi9Yj4U51lKvu+A7iJ7N/grToUGAbMjohXIuJW4EbSsU9uiIjfpua9K8jezG2AcfBbn0naW9KNqYnlObKgHlWz2Jqq4V1rxquH24AdgMWp+WAj8Is0Pa8rgQ9LGgp8GLg3Ilb3odY83g4cUqkx1Xka2dl1rV2B36dPLBWru9toWuYUsrP7tamZZN9ealnTy/zu9r1rvYX7YFdgTUS8XrPtsVXj66qGXyJ7o7ABxsFv/XER8AgwMSLeBpwDqGaZ6m5f1wK7VY3vXjX8NPBH4K8jYnj62bnqi+Veu4+NiIfIAug43tzMk7fWihfJ3oQqqkN9DXBHVY3DU3PIZ7rZzlpgRGrGqRjXQ/03R8QxwJhU6w8rs+qtUm9bSXf7rjSR9fQae/MUsLuk6twYBzzZh23YAODgt/7YCXgOeCGdnXYXftWuAT6ZvhjcATi3MiOdPf4QuEDSXwBIGivpA2mR9cAuknbuZR9XAmcBRwDX9rPWJWSfHHZIXzzPqJp3I7C3pI9JGpJ+Dkpfwr5J+rTRCXxT0raSDgf+prsdShotaWoK6peBF8iafiqvfbd6X0b3orLv95A1U1WOSU+vsbLPPepscxHZWfxX0us/Mr2uq/tRnzWRg9/648tkZ9bPk4X23J4Wjoifk32BeRvZF353p1kvp99frUxPzTG/BPZJ6z5C1l6/MjWx1GuyuIqs7f7WiHi6n7VeALxCFn4dZG3UldfwPPB+su8eniJr0jgfGFpnW39L9uX2s8A3gB/XWW4bsi++n0rLvpdNb063AsuAdZKe7n71bq0Dfp+2eQVwejqOPb7G5DygIx3rN30vEBGvkAX9cWSf1C4EPl61bWsR8oNYrNHSWfJSYKiv8TdrPJ/xW0Mou7Z+qKQRZGfKP3PomzWHg98a5dPABuB3ZNfW9/a9gJkVxE09ZmYl4zN+M7OSaYlO2kaNGhXjx49vdhlmZi1l8eLFT0fEZjdDtkTwjx8/ns7OzmaXYWbWUiR1e8e4m3rMzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiVTaPBL+mJ6LudSSVdJ2k7Zs0gXSVohaW4/u5w1M7N+Kiz4JY0FPg+0R8R+wCCyLm3PBy6IiL3Iuo6t7Q/czMwKVHRTz2Bge0mDyZ76s5bsodjXpfkdZA/lNjOzBinszt2IeFLSd4DHyR6tdwuwGNhY1R3vE7z5eZ1vkDST7CHcjBtX96l1A9r4WTc1bF+rZp/QsH2ZWWsrsqlnBDAVmED2kOYdgWPzrh8RcyKiPSLa29r68txtMzPrSZFNPe8DHouIroj4M3A98G5geGr6gewB3H5Qs5lZAxUZ/I8Dh6aHOguYAjxE9tzVk9Iy04F5BdZgZmY1Cgv+iFhE9iXuvcCDaV9zyB6s/SVJK4BdgEuKqsHMzDZXaLfMEfEN4Bs1k1cCBxe5XzMzq8937pqZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzkinyYev7SFpS9fOcpC9IGilpgaTl6feIomowM7PNFfnoxUcjYnJETAYOBF4CbgBmAQsjYiKwMI2bmVmDNKqpZwrwu4hYDUwFOtL0DmBag2owMzMaF/ynAlel4dERsTYNrwNGN6gGMzOjAcEvaVvgRODa2nkREUDUWW+mpE5JnV1dXQVXaWZWHo044z8OuDci1qfx9ZLGAKTfG7pbKSLmRER7RLS3tbU1oEwzs3JoRPB/lE3NPADzgelpeDowrwE1mJlZUmjwS9oROAa4vmrybOAYScuB96VxMzNrkMFFbjwiXgR2qZn2DNlVPmZm1gSFBr81z/hZNzVsX6tmn9CwfZnZW+cuG8zMSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiXjbplti2pkd9DgLqHN+sNn/GZmJVP0oxeHS7pO0iOSHpZ0mKSRkhZIWp5+jyiyBjMze7Oiz/i/B/wiIvYF9gceBmYBCyNiIrAwjZuZWYMUFvySdgaOAC4BiIhXImIjMBXoSIt1ANOKqsHMzDZX5Bn/BKALuEzSfZJ+JGlHYHRErE3LrANGd7eypJmSOiV1dnV1FVimmVm5FBn8g4EDgIsi4p3Ai9Q060REANHdyhExJyLaI6K9ra2twDLNzMqlyOB/AngiIhal8evI3gjWSxoDkH5vKLAGMzOrUVjwR8Q6YI2kfdKkKcBDwHxgepo2HZhXVA1mZra5om/g+hxwhaRtgZXAJ8nebK6RNANYDZxccA1mZlal0OCPiCVAezezphS5XzMzq8937pqZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVTKFP4JK0CngeeA14NSLaJY0E5gLjgVXAyRHx+yLrMDOzTRpxxn9UREyOiMojGGcBCyNiIrAwjZuZWYPkCn5JO0raJg3vLelESUP6uc+pQEca7gCm9XM7ZmbWD3mbeu4E3iNpBHALcA9wCnBaL+sFcIukAH4QEXOA0RGxNs1fB4zubkVJM4GZAOPGjctZppXZ+Fk3NXR/q2af0ND9mW0peZt6FBEvAR8GLoyIjwB/nWO9wyPiAOA44ExJR1TPjIgge3PYTETMiYj2iGhva2vLWaaZmfUmd/BLOozsDL9yWjWot5Ui4sn0ewNwA3AwsF7SmLTRMcCGvhZtZmb9lzf4vwCcDdwQEcsk7QHc1tMK6XuBnSrDwPuBpcB8YHpabDowrx91m5lZP+Vq44+IO4A7JO2QxlcCn+9ltdHADZIq+7kyIn4h6R7gGkkzgNXAyf0t3szM+i5X8KdmnkuAYcA4SfsDn46IM+qtk94c9u9m+jPAlP6Va2Zmb1Xepp5/Bz4APAMQEfcDR/S0gpmZDUy5b+CKiDU1k17bwrWYmVkD5L2Of42kdwGRbtw6C3i4uLLMzKwoec/4TwfOBMYCTwKT07iZmbWYvFf1PE3vd+mamVkL6DH4Jf0nde6sBYiI3i7pNDOzAaa3M/7OhlRhZmYN02PwR0RH9bikt2WT4/lCqzIzs8Lk7Za5XdKDwAPAUkn3Szqw2NLMzKwIeS/nvBQ4IyJ+BSDpcOAy4B1FFWZmZsXIeznna5XQB4iIu4BXiynJzMyKlPeM/w5JPwCuIrvK5xTgdkkHAETEvQXVZ2ZmW1je4K90tvaNmunvJHsjOHqLVWRmZoXKewPXUUUXYmZmjZG3W+bhwMeB8dXr+AYuM7PWk7ep57+Bu4EHgdeLK8fMWoUfbt+68gb/dhHxpUIrMTOzhsh7OedPJP2dpDGSRlZ+8qwoaZCk+yTdmMYnSFokaYWkuZK27Xf1ZmbWZ3nP+F8Bvg18jU2dtgWwR451K333vy2Nnw9cEBFXS7oYmAFclLtiswGokc0ebvKwtyrvGf/fA3tFxPiImJB+eg19SbsBJwA/SuMiu/TzurRIBzCtz1WbmVm/5Q3+FcBL/dj+vwNfYdMXwrsAGyOictfvE2QPd9mMpJmSOiV1dnV19WPXZmbWnbxNPS8CSyTdBrxcmdjT5ZySPghsiIjFko7sa2ERMQeYA9De3l73mQBmZtY3eYP//6afvng3cKKk44HtyNr4vwcMlzQ4nfXvRvYoRzMza5C8d+529L7UZuucDZwNkM74vxwRp0m6FjgJuBqYDszr67bNzKz/8vbHP1HSdZIekrSy8tPPfX4V+JKkFWRt/pf0cztmZtYPeZt6LiProO0C4Cjgk+T/YpiIuB24PQ2vBA7uS5Fvhe8utK2dLyW1vsob3ttHxEJAEbE6Is4ju0zTzMxaTN4z/pclbQMsl/RZsi9khxVXlpmZFSXvGf9ZwA7A54EDgY+RfTFrZmYtJu9VPfekwRckzQCGRcRzxZVlZmZFyXtVz5WS3iZpR2Ap8JCkfyi2NDMzK0Lepp5J6Qx/GvBzYAJZc4+ZmbWYvME/RNIQsuCfHxF/ZlMvnWZm1kLyBv/FwCpgR+BOSW8H3MZvZtaC8l7OuXNEjAWQNBR4nOxGLjMzazE9nvFL+qqkw8j61qn4TWRerbeemZkNXL2d8T8CfATYQ9Kv0vgukvaJiEcLr87MzLa43tr4NwLnkD2I5UiybpUBZkn6n+LKMjOzovR2xv8B4OvAnsB3gQeAFyPik0UXZmZmxejxjD8izomIKWRX9PwEGAS0SbpL0s8aUJ+ZmW1hea/quTkiOoFOSZ+JiMMljSqyMDMzK0au6/gj4itVo59I054uoiAzMytW7oepVETE/UUUYmZmjdHn4M9L0naSfivpfknLJH0zTZ8gaZGkFZLmStq2qBrMzGxzhQU/8DJwdETsD0wGjpV0KHA+cEFE7AX8HphRYA1mZlajsOBPd/e+kEaHpJ8AjgauS9M7yDp+MzOzBinyjB9JgyQtATYAC4DfARurunt4AhhbZ92ZkjoldXZ1dRVZpplZqRQa/BHxWkRMBnYDDgb27cO6cyKiPSLa29raiirRzKx0Cg3+iojYCNwGHAYMl1S5f2A3sge3m5lZgxR5VU+bpOFpeHvgGOBhsjeASm+f04F5RdVgZmaby3vnbn+MATokDSJ7g7kmIm6U9BBwtaRvAfcBlxRYg5mZ1Sgs+CPiAeCd3UxfSdbeb2ZmTdCQNn4zMxs4HPxmZiXj4DczKxkHv5lZyTj4zcxKxsFvZlYyDn4zs5Jx8JuZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGSKfObu7pJuk/SQpGWSzkrTR0paIGl5+j2iqBrMzGxzRZ7xvwr8fURMAg4FzpQ0CZgFLIyIicDCNG5mZg1SWPBHxNqIuDcNPw88DIwFpgIdabEOYFpRNZiZ2eYa0sYvaTzZg9cXAaMjYm2atQ4YXWedmZI6JXV2dXU1okwzs1IoPPglDQN+CnwhIp6rnhcRAUR360XEnIhoj4j2tra2oss0MyuNQoNf0hCy0L8iIq5Pk9dLGpPmjwE2FFmDmZm9WZFX9Qi4BHg4Ir5bNWs+MD0NTwfmFVWDmZltbnCB23438DHgQUlL0rRzgNnANZJmAKuBkwuswczMahQW/BFxF6A6s6cUtV8zM+uZ79w1MysZB7+ZWckU2cZvZlaI8bNuauj+Vs0+oaH7K5rP+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiVT5DN3L5W0QdLSqmkjJS2QtDz9HlHU/s3MrHtFnvFfDhxbM20WsDAiJgIL07iZmTVQYcEfEXcCz9ZMngp0pOEOYFpR+zczs+41uo1/dESsTcPrgNH1FpQ0U1KnpM6urq7GVGdmVgJN+3I3IgKIHubPiYj2iGhva2trYGVmZlu3Rgf/ekljANLvDQ3ev5lZ6TU6+OcD09PwdGBeg/dvZlZ6RV7OeRXwG2AfSU9ImgHMBo6RtBx4Xxo3M7MGGlzUhiPio3VmTSlqn2Zm1jvfuWtmVjIOfjOzknHwm5mVjIPfzKxkCvty18xsazR+1k0N29eq2ScUsl2f8ZuZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrmaYEv6RjJT0qaYWkWc2owcysrBoe/JIGAd8HjgMmAR+VNKnRdZiZlVUzzvgPBlZExMqIeAW4GpjahDrMzEpJEdHYHUonAcdGxKfS+MeAQyLiszXLzQRmptF9gEcbWmjvRgFPN7uIt8D1N5frb66y1P/2iGirnThgH8QSEXOAOc2uox5JnRHR3uw6+sv1N5frb66y19+Mpp4ngd2rxndL08zMrAGaEfz3ABMlTZC0LXAqML8JdZiZlVLDm3oi4lVJnwVuBgYBl0bEskbXsQUM2GaonFx/c7n+5ip1/Q3/ctfMzJrLd+6amZWMg9/MrGQc/DlJWiXpQUlLJHWmaSMlLZC0PP0e0ew6KyRdKmmDpKVV07qtV5n/SF1oPCDpgOZV/kat3dV/nqQn07/BEknHV807O9X/qKQPNKfqN2rZXdJtkh6StEzSWWl6Sxz/HupvleO/naTfSro/1f/NNH2CpEWpzrnp4hIkDU3jK9L88QO0/sslPVZ1/Cen6X3/+4kI/+T4AVYBo2qm/SswKw3PAs5vdp1VtR0BHAAs7a1e4Hjg54CAQ4FFA7T+84Avd7PsJOB+YCgwAfgdMKiJtY8BDkjDOwH/L9XYEse/h/pb5fgLGJaGhwCL0nG9Bjg1Tb8Y+EwaPgO4OA2fCsxt8vGvV//lwEndLN/nvx+f8b81U4GONNwBTGteKW8WEXcCz9ZMrlfvVODHkbkbGC5pTEMKraNO/fVMBa6OiJcj4jFgBVnXIE0REWsj4t40/DzwMDCWFjn+PdRfz0A7/hERL6TRIekngKOB69L02uNf+Xe5DpgiSY2pdnM91F9Pn/9+HPz5BXCLpMWpOwmA0RGxNg2vA0Y3p7Tc6tU7FlhTtdwT9PwfvZk+mz7OXlrVtDZg60/NBu8kO2trueNfUz+0yPGXNEjSEmADsIDsU8jGiHg1LVJd4xv1p/l/AHZpaME1auuPiMrx/6d0/C+QNDRN6/Pxd/Dnd3hEHEDWq+iZko6onhnZZ66WuTa21epNLgL2BCYDa4F/a2o1vZA0DPgp8IWIeK56Xisc/27qb5njHxGvRcRksp4BDgb2bW5FfVNbv6T9gLPJXsdBwEjgq/3dvoM/p4h4Mv3eANxA9se0vvKRKv3e0LwKc6lXb0t0oxER69N/iNeBH7KpOWHA1S9pCFloXhER16fJLXP8u6u/lY5/RURsBG4DDiNrAqnctFpd4xv1p/k7A880ttLuVdV/bGqCi4h4GbiMt3D8Hfw5SNpR0k6VYeD9wFKyriamp8WmA/OaU2Fu9eqdD3w8XR1wKPCHqiaJAaOm3fJDZP8GkNV/aro6YwIwEfhto+urSO3DlwAPR8R3q2a1xPGvV38LHf82ScPT8PbAMWTfU9wGnJQWqz3+lX+Xk4Bb0yeypqhT/yNVJw0i+36i+vj37e+nmd9et8oPsAfZVQv3A8uAr6XpuwALgeXAL4GRza61quaryD6O/5mszW9GvXrJrgb4Plk76INA+wCt/yepvgfSH/uYquW/lup/FDiuybUfTtaM8wCwJP0c3yrHv4f6W+X4vwO4L9W5FPh6mr4H2RvSCuBaYGiavl0aX5Hm7zFA6781Hf+lwH+x6cqfPv/9uMsGM7OScVOPmVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPftgqShks6o0H7miZp0hba1nmSvrwltmWWl4PfthbDyXpZzC3d8NKf/wPTyHqkNGtJDn7bWswG9kz9lH9b0jBJCyXdq+w5ClMh63RMWZ/xPya7EWZ3SeemaXdJuqpyBi5pT0m/SB3z/UrSvpLeBZwIfDvta89KAZJ2lrS68maS7vheI2mIpL+TdI+yPtZ/KmmH2hcg6XZJ7Wl4lKRVaXhQek33pA66Pl3sobStXcMftm5WkFnAfpF1bFXpc+VDEfGcpFHA3ZLmp2UnAtMj4m5JBwH/C9ifrPvbe4HFabk5wOkRsVzSIcCFEXF02s6NEXEdVSLiD6lHxfeSdQ/wQeDmiPizpOsj4oeptm+R3Yn8nzlf2wyy2/APSj0y/lrSLZF1gWzWZw5+21oJ+OfUi+rrZN3UVrpBXh1Zv+UA7wbmRcSfgD9J+hm80TPlu4Brtalr9ko3uD2ZC5xCFvynAhem6fulwB8ODANu7sNreT/wDkmVfmZ2JnvzcvBbvzj4bWt1GtAGHJjOuFeR9ckC8GKO9bch6799ch/3O5/sDWckcCBZ/yqQPT1pWkTcL+kTwJHdrPsqm5pft6uaLuBzEdGXNwuzutzGb1uL58keE1ixM7Ahhf5RwNvrrPdr4G+UPed0GFnzDJH1P/+YpI/AG18E719nX2+I7MlJ9wDfI2sOei3N2glYm7o7Pq1OLavI3ixgUy+SkH06+ExaF0l7p15izfrFwW9bhYh4hqzte6mkbwNXAO2SHgQ+DjxSZ717yM7SHyB7bumDZE9ggiygZ0iq9Mo6NU2/GvgHSfdVf7lbZS7wv9PvinPJnmL163q1AN8hC/j7gFFV038EPATcq+zh8z/An9btLXDvnFZ6koZFxAvpSps7gZmRnjlrtjXyWYMZzEk3ZG0HdDj0bWvnM34zs5JxG7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZXM/wcLRMohVH8V9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() \n",
    "reg.fit(X_train, y_train)\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "np.round(reg_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret model coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a97b88",
   "metadata": {},
   "source": [
    "**Your task**: write down the linear regression model with the above coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a435a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = 151.008 + 29.254 * age + (-261.706) * sex + 546.3 * bmi + 388.398 * bp + (-901.96) * x1 + 506.763 * x2 + 121.154 * x3 + 288.03 * x4 + 659.269 * x5 + 41.377 * x6 + error_term'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"y = 151.008 + 29.254 * age + (-261.706) * sex + 546.3 * bmi + 388.398 * bp + (-901.96) * x1 + 506.763 * x2 + 121.154 * x3 + 288.03 * x4 + 659.269 * x5 + 41.377 * x6 + error_term\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**Your task**: explore other parameters/attributes/methods\n",
    "- fit_intercept\n",
    "- feature_names_in_, n_features_in_\n",
    "Write your exploration code and results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used:  10\n",
      "Names of features:  ['age' 'sex' 'bmi' 'bp' 's1' 's2' 's3' 's4' 's5' 's6']\n",
      "Model Score:  0.477\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"Number of features used: \", reg.n_features_in_)\n",
    "print(\"Names of features: \", reg.feature_names_in_)\n",
    "\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "print(\"Model Score: \", np.round(reg_score, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "np.round(rg_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Your task: fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c416398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "lasso_reg_score = lasso_reg.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c90cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Score:  0.362\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "print(\"Lasso Regression Score: \", np.round(lasso_reg_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.     -0.    443.703  51.601   0.      0.     -0.      0.    201.966\n",
      "   0.   ]\n",
      "152.166\n"
     ]
    }
   ],
   "source": [
    "# Interpret model coefficients and intercept\n",
    "print(np.round(lasso_reg.coef_,3))\n",
    "print(np.round(lasso_reg.intercept_,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Your task: compare the linear/ridge/lasso regression models\n",
    "- write down your code to create and display the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e90c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254013</td>\n",
       "      <td>45.054210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706469</td>\n",
       "      <td>-71.947397</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.299723</td>\n",
       "      <td>280.716252</td>\n",
       "      <td>443.703388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398341</td>\n",
       "      <td>195.212662</td>\n",
       "      <td>51.601094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.959668</td>\n",
       "      <td>-2.229303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763241</td>\n",
       "      <td>-17.540797</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154351</td>\n",
       "      <td>-148.688862</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035267</td>\n",
       "      <td>120.467240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.268951</td>\n",
       "      <td>198.614401</td>\n",
       "      <td>201.966478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.376701</td>\n",
       "      <td>106.934692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008213</td>\n",
       "      <td>151.867464</td>\n",
       "      <td>152.165919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477290</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>0.361898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               linear       ridge       lasso\n",
       "age         29.254013   45.054210    0.000000\n",
       "sex       -261.706469  -71.947397   -0.000000\n",
       "bmi        546.299723  280.716252  443.703388\n",
       "bp         388.398341  195.212662   51.601094\n",
       "s1        -901.959668   -2.229303    0.000000\n",
       "s2         506.763241  -17.540797    0.000000\n",
       "s3         121.154351 -148.688862   -0.000000\n",
       "s4         288.035267  120.467240    0.000000\n",
       "s5         659.268951  198.614401  201.966478\n",
       "s6          41.376701  106.934692    0.000000\n",
       "intercept  151.008213  151.867464  152.165919\n",
       "score        0.477290    0.423344    0.361898"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure to: \n",
    "# - round to 3 digits after the decimal point\n",
    "# - rename the column names \n",
    "# - include intercept and score in the last two rows\n",
    "df_coefs = pd.DataFrame({\n",
    "    'linear': np.append(reg.coef_, [reg.intercept_, reg_score]),\n",
    "    'ridge': np.append(rg_reg.coef_, [rg_reg.intercept_, rg_reg_score]),\n",
    "    'lasso': np.append(lasso_reg.coef_, [lasso_reg.intercept_, lasso_reg_score])\n",
    "})\n",
    "\n",
    "feature_names = list(reg.feature_names_in_)\n",
    "feature_names += ['intercept', 'score'] \n",
    "df_coefs.index = feature_names\n",
    "\n",
    "df_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eadf9ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"adding regularization inevitably reduce the performance of the regression model, which is also known as the bias-variance trade-off, saying that we are willing to scarifice some model's accuracy in order to make it perform and generalize better on the unseen data. The biggest difference between ridge and lasso is that lasso can reduce some coefficient all the way to zero so that it's a good way for eliminating irrelevant variables when building regression models\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"adding regularization inevitably reduce the performance of the regression model, which is also known as the bias-variance trade-off, saying that \\\n",
    "we are willing to scarifice some model's accuracy in order to make it perform and generalize better on the unseen data. The biggest difference between \\\n",
    "ridge and lasso is that lasso can reduce some coefficient all the way to zero so that it's a good way for eliminating irrelevant variables when building regression models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models \n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63b3c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151.00821291456543, -360.91876865689113, 2.3716369301102596e+16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Polynomial transformation for degree 1\n",
    "poly1 = PolynomialFeatures(degree=1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly1, y_train)\n",
    "intercept_poly1 = lin_reg.intercept_\n",
    "\n",
    "# Polynomial transformation for degree 2\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly2, y_train)\n",
    "intercept_poly2 = lin_reg.intercept_\n",
    "\n",
    "# Polynomial transformation for degree 3\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly3, y_train)\n",
    "intercept_poly3 = lin_reg.intercept_\n",
    "\n",
    "(intercept_poly1, intercept_poly2, intercept_poly3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poly_d1': 0.4772897164322618,\n",
       " 'poly_d2': 0.41297706916210775,\n",
       " 'poly_d3': -92.13590766033613}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "for degree in range(1, 4):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    lin_reg.fit(X_train_poly, y_train)\n",
    "    scores[f'poly_d{degree}'] = lin_reg.score(X_test_poly, y_test)\n",
    "\n",
    "poly1_score = scores['poly_d1']\n",
    "poly2_score = scores['poly_d2']\n",
    "poly3_score = scores['poly_d3']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Your task: compare the polynomial regression models with degree=1/2/3 and the original linear regression model\n",
    "- please write code to create and display the given data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f9e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>poly_d1</th>\n",
       "      <th>poly_d2</th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.00800</td>\n",
       "      <td>151.00800</td>\n",
       "      <td>-360.919000</td>\n",
       "      <td>2.371637e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.47729</td>\n",
       "      <td>0.47729</td>\n",
       "      <td>0.412977</td>\n",
       "      <td>-9.213591e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              linear    poly_d1     poly_d2       poly_d3\n",
       "intercept  151.00800  151.00800 -360.919000  2.371637e+16\n",
       "score        0.47729    0.47729    0.412977 -9.213591e+01"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'linear': [round(reg.intercept_,3), reg_score],\n",
    "    'poly_d1': [round(intercept_poly1,3), poly1_score],\n",
    "    'poly_d2': [round(intercept_poly2,3), poly2_score],\n",
    "    'poly_d3': [round(intercept_poly3,3), poly3_score]\n",
    "},\n",
    "index=['intercept', 'score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your task: observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7aba6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As the degree of the polynomial features increases, the complexity of the model also increases. A simple linear regression (degree 1) might underfit the data if the true relationship is not linear. Polynomial regression with degree 2 or 3 might fit the data better if the relationship is indeed quadratic or cubic. A decreasing score as the degree increases suggests that adding complexity (more degrees) is not adding value and may be detrimental'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"As the degree of the polynomial features increases, the complexity of the model also increases. A simple linear regression (degree 1) might underfit the data if the true relationship is not linear. \\\n",
    "Polynomial regression with degree 2 or 3 might fit the data better if the relationship is indeed quadratic or cubic. A decreasing score as the degree increases suggests that adding complexity \\\n",
    "(more degrees) is not adding value and may be detrimental\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Your task: interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute positively/negatively/most/least to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56641a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The linear and ridge models suggest that age is positively associated with diabetes, which makes sense as the risk of type 2 diabetes increases with age. BMI and BP are consistently positive across models, suggesting they contribute to an increased risk or severity of diabetes. BMI seems to have the largest positive coefficient consistently across models, indicating it could be one of the most influential factors in this dataset.The feature represented as 'sex' in the linear model has a negative coefficient, suggesting it may contribute to a lower risk or severity, but this is not consistent across models.    \""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The linear and ridge models suggest that age is positively associated with diabetes, which makes sense as the risk of type 2 diabetes increases with age. \\\n",
    "BMI and BP are consistently positive across models, suggesting they contribute to an increased risk or severity of diabetes. BMI seems to have the largest positive coefficient consistently across models, indicating it could be one of the most influential factors in this dataset.\\\n",
    "The feature represented as 'sex' in the linear model has a negative coefficient, suggesting it may contribute to a lower risk or severity, but this is not consistent across models.    \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('/Users/lijiazheng/Desktop/wangzhao winter/banknote_authentication_dataframe.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb9b2",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- L1 VS L2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e206acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb8b57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0baa21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2525662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [0.996, 0.004]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff19c",
   "metadata": {},
   "source": [
    "**Your task**: explore at least one different set of parameters to re-fit the model: solver, penalty, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "598e50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=0.2).fit(X_train, y_train)\n",
    "clf_test_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cf5ea6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_2 = LogisticRegression(random_state=0, solver='newton-cg', penalty='l2', C=0.2).fit(X_train, y_train)\n",
    "clf_test_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a43a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_3 = LogisticRegression(random_state=0, C=0.3).fit(X_train, y_train)\n",
    "clf_test_3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "     \n",
    "    # set the model parameter c to different values and train the model \n",
    "    # for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    #    fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "    #    test and record the model performance \n",
    "    #    get the statistical information about the model coefficients: \n",
    "    #        min: minimum coefficient\n",
    "    #        max: minimum coefficient\n",
    "    #        mean(abs(coef)): average over the absolute coefficient values\n",
    "    #        n_zero: number of coefficients equal to zero \n",
    "    \n",
    "    ### Your code starts from here \n",
    "    df_list = []\n",
    "    \n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        clf = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', penalty=p, C=c).fit(X_train, y_train)\n",
    "        # Retrieve the coefficients of the LogisticRegression model\n",
    "        coef = clf.coef_\n",
    "        # Get statistical information about the model coefficients, as well as model performance (test_score)\n",
    "        df = [c, coef.min(), coef.max(), abs(coef).mean(), (coef == 0).sum(), clf.score(X_test, y_test)]\n",
    "        df = pd.DataFrame(df).T\n",
    "        df.columns = [\"c\", \"min\", \"max\", \"mean_abs\", \"n_zero\", \"test_score\"]\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # Concatenate model performance with different c\n",
    "    df = pd.concat(df_list)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return clf, df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7fb1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357242</td>\n",
       "      <td>-0.074218</td>\n",
       "      <td>0.189712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.860815</td>\n",
       "      <td>-0.172662</td>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.580581</td>\n",
       "      <td>-0.162763</td>\n",
       "      <td>0.915028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.834711</td>\n",
       "      <td>-0.166099</td>\n",
       "      <td>1.645101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171020</td>\n",
       "      <td>-0.289579</td>\n",
       "      <td>2.936961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.647564</td>\n",
       "      <td>-0.437990</td>\n",
       "      <td>4.297064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c       min       max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.357242 -0.074218  0.189712     0.0    0.922330\n",
       "1    0.010 -0.860815 -0.172662  0.485241     0.0    0.973301\n",
       "2    0.100 -1.580581 -0.162763  0.915028     0.0    0.987864\n",
       "3    1.000 -2.834711 -0.166099  1.645101     0.0    0.987864\n",
       "4   10.000 -5.171020 -0.289579  2.936961     0.0    0.987864\n",
       "5  100.000 -7.647564 -0.437990  4.297064     0.0    0.990291"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l2_clfs, c_effect_l2 = compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "c_effect_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bd278a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.041929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.623786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.917476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.750236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.838485</td>\n",
       "      <td>-0.132006</td>\n",
       "      <td>2.163931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.109730</td>\n",
       "      <td>-0.388707</td>\n",
       "      <td>3.992891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.196342</td>\n",
       "      <td>-0.463991</td>\n",
       "      <td>4.595852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c       min       max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.041929  0.000000  0.010482     3.0    0.623786\n",
       "1    0.010 -0.807180  0.000000  0.327752     1.0    0.917476\n",
       "2    0.100 -1.750236  0.000000  0.935861     1.0    0.987864\n",
       "3    1.000 -3.838485 -0.132006  2.163931     0.0    0.987864\n",
       "4   10.000 -7.109730 -0.388707  3.992891     0.0    0.990291\n",
       "5  100.000 -8.196342 -0.463991  4.595852     0.0    0.990291"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l1_clfs, c_effect_l1 = compare_c(X_train, y_train, X_test, y_test, p='l1')\n",
    "c_effect_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "**Your thoughts and observations:** \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68efdf3",
   "metadata": {},
   "source": [
    "- A smaller C value leads to stronger regularization, which increases bias but reduces variance, potentially addressing overfitting. A larger C value decreases regularization strength, allowing the model to increase its variance but potentially leading to overfitting.\n",
    "With an L1 penalty, as C decreases (stronger regularization), more coefficients are driven to zero, simplifying the model. This can help in reducing overfitting but might increase the risk of underfitting if C is too small.\n",
    "With an L2 penalty, decreasing C (increasing regularization) shrinks the coefficients towards zero but keeps all features in the model. This can help in reducing overfitting by penalizing large coefficients, without the risk of eliminating potentially important features.\n",
    "\n",
    "- L1 Penalty (Lasso Regularization) tends to produce sparse models by driving some coefficients to exactly zero, thus performing feature selection. This can be beneficial in high-dimensional datasets where some features are irrelevant or redundant. L2 Penalty (Ridge Regularization) shrinks the coefficients towards zero but typically does not set any to zero. The difference between using L1 and L2 regularization affects model complexity, the likelihood of overfitting or underfitting, and the interpretability of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0440979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.68613708, -0.94725836, -1.12472807,  0.0193013 ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d62802",
   "metadata": {},
   "source": [
    "This part clarifies the relationship between regularizatons and overfitting/underfitting, as matter a fact they are highly correlated which is also known as \n",
    "the bias-variance trade-off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
